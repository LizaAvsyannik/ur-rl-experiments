import rospy
import gym
from gym.utils import seeding
from .gazebo_connection import GazeboConnection
from .controllers_connection import ControllersConnection

class RobotGazeboEnv(gym.GoalEnv):

    def __init__(self, controllers_list):
        self.controllers_list = controllers_list
        self.gazebo = GazeboConnection()
        self.controllers_object = ControllersConnection(controllers_list=controllers_list)
        self.seed()
        self.episode_num = 0

    # Env methods
    def seed(self, seed=None):
        self.np_random, seed = seeding.np_random(seed)
        return [seed]

    def step(self, action):
        """
        Function executed each time step.
        Here we get the action execute it in a time step and retrieve the
        observations generated by that action.
        :param action:
        :return: obs, reward, done, info
        """
        rospy.logdebug("Entered step")
        rospy.logdebug("Unpause sim")
        self.gazebo.unpauseSim()
        rospy.logdebug("Set action")
        rospy.logdebug(f"Action: {action}")
        self._set_action(action.squeeze())
        rospy.logdebug("Is done")
        done = self._is_done()
        rospy.logdebug("Get Obs")
        obs = self._get_obs()
        reward, done, info = self._compute_reward(obs, done)
        self._reset_env_state()
        return obs, reward, done, info

    def reset(self):
        rospy.logdebug("Reseting RobotGazeboEnvironment")
        self._reset_env_state()
        self._reset_sim()
        self._update_episode()
        obs = self._get_obs()
        self._init_env_variables()
        return obs

    def close(self):
        """
        Function executed when closing the environment.
        Use it for closing GUIS and other systems that need closing.
        :return:
        """
        rospy.logdebug("Closing RobotGazeboEnvironment")
        rospy.signal_shutdown("Closing RobotGazeboEnvironment")

    def _update_episode(self):
        """
        Increases the episode number by one
        :return:
        """
        self.episode_num += 1

    # Extension methods
    # ----------------------------
    def _reset_env_state(self):
        """Resets accumulated environment state
        """
        raise NotImplementedError()

    def _reset_sim(self):
        """Resets a simulation
        """
        raise NotImplementedError()

    def _set_init_pose(self):
        """Sets the Robot in its init pose
        """
        raise NotImplementedError()

    def _check_all_systems_ready(self):
        """
        Checks that all the sensors, publishers and other simulation systems are
        operational.
        """
        raise NotImplementedError()

    def _get_obs(self):
        """Returns the observation.
        """
        raise NotImplementedError()

    def _init_env_variables(self):
        """Inits variables needed to be initialised each time we reset at the start
        of an episode.
        """
        raise NotImplementedError()

    def _set_action(self, action):
        """Applies the given action to the simulation.
        """
        raise NotImplementedError()

    def _is_done(self):
        """Indicates whether or not the episode is done ( the robot has fallen for example).
        """
        raise NotImplementedError()

    def _compute_reward(self, observations, done):
        """Calculates the reward to give based on the observations given.
        """
        raise NotImplementedError()

    def _env_setup(self, initial_qpos):
        """Initial configuration of the environment. Can be used to configure initial state
        and extract information from the simulation.
        """
        raise NotImplementedError()
        